{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models.mobilenetv3 import mobilenet_v3_small\n",
    "from torchvision.models.resnet import resnet18\n",
    "\n",
    "import nni\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def build_mobilenet_v3():\n",
    "    model = mobilenet_v3_small(pretrained=True)\n",
    "    model.classifier[-1] = torch.nn.Linear(1024, 10)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def build_resnet18():\n",
    "    model = resnet18(pretrained=True)\n",
    "    model.fc = torch.nn.Linear(512, 10)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def prepare_dataloader(batch_size: int = 128):\n",
    "    normalize = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    train_loader = DataLoader(\n",
    "        datasets.CIFAR10(Path(__file__).parent / 'data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        datasets.CIFAR10(Path(__file__).parent / 'data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def prepare_optimizer(model: torch.nn.Module):\n",
    "    optimize_params = [param for param in model.parameters() if param.requires_grad == True]\n",
    "    optimizer = nni.trace(Adam)(optimize_params, lr=0.001)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module, optimizer: torch.optim.Optimizer, training_step,\n",
    "          lr_scheduler: _LRScheduler, max_steps: int, max_epochs: int):\n",
    "    assert max_epochs is not None or max_steps is not None\n",
    "    train_loader, test_loader = prepare_dataloader()\n",
    "    max_steps = max_steps if max_steps else max_epochs * len(train_loader)\n",
    "    max_epochs = max_steps // len(train_loader) + (0 if max_steps % len(train_loader) == 0 else 1)\n",
    "    count_steps = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = training_step((data, target), model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count_steps += 1\n",
    "            if count_steps >= max_steps:\n",
    "                acc = evaluate(model, test_loader)\n",
    "                print(f'[Training Epoch {epoch} / Step {count_steps}] Final Acc: {acc}%')\n",
    "                return\n",
    "        acc = evaluate(model, test_loader)\n",
    "        print(f'[Training Epoch {epoch} / Step {count_steps}] Final Acc: {acc}%')\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return 100 * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def training_step(batch, model: torch.nn.Module):\n",
    "    output = model(batch[0])\n",
    "    loss = F.cross_entropy(output, batch[1])\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT license.\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(__file__).absolute().parents[1]))\n",
    "\n",
    "import torch\n",
    "\n",
    "# from models import (\n",
    "#     build_resnet18,\n",
    "#     prepare_dataloader,\n",
    "#     prepare_optimizer,\n",
    "#     train,\n",
    "#     training_step,\n",
    "#     evaluate,\n",
    "#     device\n",
    "# )\n",
    "\n",
    "from nni.compression.pytorch import TorchEvaluator\n",
    "from nni.compression.pytorch.pruning import SlimPruner\n",
    "# from nni.compression.pytorch import auto_set_denpendency_group_ids\n",
    "from nni.compression.pytorch import ModelSpeedup\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # finetuning resnet18 on Cifar10\n",
    "    model = build_resnet18()\n",
    "    optimizer = prepare_optimizer(model)\n",
    "    train(model, optimizer, training_step, lr_scheduler=None, max_steps=None, max_epochs=10)\n",
    "    _, test_loader = prepare_dataloader()\n",
    "    print('Original model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "    print('Original model after 10 epochs finetuning acc: ', evaluate(model, test_loader), '%')\n",
    "\n",
    "    config_list = [{\n",
    "        'op_types': ['Conv2d','Linear'],\n",
    "        'sparse_ratio': 0.7\n",
    "    }]\n",
    "    dummy_input = torch.rand(8, 3, 224, 224).to(device)\n",
    "    # config_list = auto_set_denpendency_group_ids(model, config_list, dummy_input)\n",
    "    optimizer = prepare_optimizer(model)\n",
    "    evaluator = TorchEvaluator(train, optimizer, training_step)\n",
    "\n",
    "    pruner = SlimPruner(model, config_list, evaluator, training_steps=1000)\n",
    "\n",
    "    _, masks = pruner.compress()\n",
    "    pruner.unwrap_model()\n",
    "\n",
    "    model = ModelSpeedup(model, dummy_input, masks).speedup_model()\n",
    "    print('Pruned model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "    print('Pruned model without finetuning acc: ', evaluate(model, test_loader), '%')\n",
    "\n",
    "    optimizer = prepare_optimizer(model)\n",
    "    train(model, optimizer, training_step, lr_scheduler=None, max_steps=None, max_epochs=10)\n",
    "    _, test_loader = prepare_dataloader()\n",
    "    print('Pruned model after 10 epochs finetuning acc: ', evaluate(model, test_loader), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT license.\n",
    "import sys\n",
    "sys.path.append(r'D:\\31890\\Desktop\\codefile\\Utils')\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from model__ import segformer_m,segnet\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = segnet()\n",
    "    torch.save(model,r'D:\\31890\\Desktop\\codefile\\Utils\\Packages\\prune__\\test\\para1.pt')\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # prune 20% of connections in all 2D-conv layers\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "        # prune 40% of connections in all linear layers\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            prune.l1_unstructured(module, name='weight', amount=0.4)\n",
    "    \n",
    "    torch.save(model,r'D:\\31890\\Desktop\\codefile\\Utils\\Packages\\prune__\\test\\para2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r'D:\\31890\\Desktop\\codefile\\Utils')\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from model__ import ViT, channel_selection\n",
    "from model__ import ViT_slim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cudnn.benchmark = True\n",
    "\n",
    "model = ViT(\n",
    "    image_size = 32,\n",
    "    patch_size = 4,\n",
    "    num_classes = 10,\n",
    "    dim = 512,                  # 512\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    "    )\n",
    "model = model.to(device)\n",
    "\n",
    "model_path = \"checkpoint/pruning-adamw-vit-4-79.84.t7\"\n",
    "print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "checkpoint = torch.load(model_path)\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_prec1 = checkpoint['acc']\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\".format(model_path, checkpoint['epoch'], best_prec1))\n",
    "\n",
    "total = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, channel_selection):\n",
    "        total += m.indexes.data.shape[0]\n",
    "\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, channel_selection):\n",
    "        size = m.indexes.data.shape[0]\n",
    "        bn[index:(index+size)] = m.indexes.data.abs().clone()\n",
    "        index += size\n",
    "\n",
    "percent = 0.3\n",
    "y, i = torch.sort(bn)\n",
    "thre_index = int(total * percent)\n",
    "thre = y[thre_index]\n",
    "\n",
    "# print(thre)\n",
    "\n",
    "pruned = 0\n",
    "cfg = []\n",
    "cfg_mask = []\n",
    "for k, m in enumerate(model.modules()):\n",
    "    if isinstance(m, channel_selection):\n",
    "        # print(k)\n",
    "        # print(m)\n",
    "        if k in [16,40,64,88,112,136]:\n",
    "            weight_copy = m.indexes.data.abs().clone()\n",
    "            mask = weight_copy.gt(thre).float().cuda()\n",
    "            thre_ = thre.clone()\n",
    "            while (torch.sum(mask)%8 !=0):                       # heads\n",
    "                thre_ = thre_ - 0.0001\n",
    "                mask = weight_copy.gt(thre_).float().cuda()\n",
    "        else:\n",
    "            weight_copy = m.indexes.data.abs().clone()\n",
    "            mask = weight_copy.gt(thre).float().cuda()\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "        m.indexes.data.mul_(mask)\n",
    "        cfg.append(int(torch.sum(mask)))\n",
    "        cfg_mask.append(mask.clone())\n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "\n",
    "pruned_ratio = pruned/total\n",
    "print('Pre-processing Successful!')\n",
    "print(cfg)\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    testset = torchvision.datasets.CIFAR10(root='/home/lxc/ABCPruner/data', train=False, download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print('Acc: %.3f%% (%d/%d)' % (100.*correct/total, correct, total))\n",
    "\n",
    "test(model)\n",
    "cfg_prune = []\n",
    "for i in range(len(cfg)):\n",
    "    if i%2!=0:\n",
    "        cfg_prune.append([cfg[i-1],cfg[i]])\n",
    "\n",
    "newmodel = ViT_slim(image_size = 32,\n",
    "    patch_size = 4,\n",
    "    num_classes = 10,\n",
    "    dim = 512,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    cfg=cfg_prune)\n",
    "\n",
    "newmodel.to(device)\n",
    "# num_parameters = sum([param.nelement() for param in newmodel.parameters()])\n",
    "\n",
    "newmodel_dict = newmodel.state_dict().copy()\n",
    "\n",
    "i = 0\n",
    "newdict = {}\n",
    "for k,v in model.state_dict().items():\n",
    "    if 'net1.0.weight' in k:\n",
    "        # print(k)\n",
    "        # print(v.size())\n",
    "        # print('----------')\n",
    "        idx = np.squeeze(np.argwhere(np.asarray(cfg_mask[i].cpu().numpy())))\n",
    "        newdict[k] = v[idx.tolist()].clone()\n",
    "    elif 'net1.0.bias' in k:\n",
    "        # print(k)\n",
    "        # print(v.size())\n",
    "        # print('----------')\n",
    "        idx = np.squeeze(np.argwhere(np.asarray(cfg_mask[i].cpu().numpy())))\n",
    "        newdict[k] = v[idx.tolist()].clone()\n",
    "    elif 'to_q' in k or 'to_k' in k or 'to_v' in k:\n",
    "        # print(k)\n",
    "        # print(v.size())\n",
    "        # print('----------')\n",
    "        idx = np.squeeze(np.argwhere(np.asarray(cfg_mask[i].cpu().numpy())))\n",
    "        newdict[k] = v[idx.tolist()].clone()\n",
    "    elif 'net2.0.weight' in k:\n",
    "        # print(k)\n",
    "        # print(v.size())\n",
    "        # print('----------')\n",
    "        idx = np.squeeze(np.argwhere(np.asarray(cfg_mask[i].cpu().numpy())))\n",
    "        newdict[k] = v[:,idx.tolist()].clone()\n",
    "        i = i + 1\n",
    "    elif 'to_out.0.weight' in k:\n",
    "        # print(k)\n",
    "        # print(v.size())\n",
    "        # print('----------')\n",
    "        idx = np.squeeze(np.argwhere(np.asarray(cfg_mask[i].cpu().numpy())))\n",
    "        newdict[k] = v[:,idx.tolist()].clone()\n",
    "        i = i + 1\n",
    "\n",
    "    elif k in newmodel.state_dict():\n",
    "        newdict[k] = v\n",
    "\n",
    "newmodel_dict.update(newdict)\n",
    "newmodel.load_state_dict(newmodel_dict)\n",
    "\n",
    "torch.save(newmodel.state_dict(), 'pruned.pth')\n",
    "print('after pruning: ', end=' ')\n",
    "test(newmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
