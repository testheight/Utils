{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from time import time # 用于计算运行时间\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2,os,tqdm\n",
    "from matplotlib import offsetbox # 定义图形box的格式\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection) \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  聚类算法  sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单张图片像素数聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_count_pixel(img_file,save_file):\n",
    "    if not os.path.exists(save_file):\n",
    "        os.makedirs(save_file)\n",
    "    for name in tqdm.tqdm(os.listdir(img_file)):\n",
    "        img_path = os.path.join(img_file,name)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        img_copy = img\n",
    "        pixel_list = []\n",
    "        df1_dict = {}\n",
    "        for num in range(256):\n",
    "            pixel_list.append(np.sum(img==num))\n",
    "        df1_dict[str(name.split('.')[0])] = pixel_list\n",
    "        data=pd.DataFrame(df1_dict)\n",
    "        data = data.drop([0])\n",
    "        data = data[~(data.isin([0]))]\n",
    "        data = data.dropna(axis=0,how='any')\n",
    "        data = data.astype(int)\n",
    "        data_index = np.array(data.index)\n",
    "        # 由于几个特征的量纲差距很大，聚类前必须进行归一化\n",
    "        cluster_data = preprocessing.scale(data)\n",
    "        # data数据进行归一化\n",
    "        cluster_data = cluster_data.reshape(-1,1)\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        cluster_data = min_max_scaler.fit_transform(cluster_data)\n",
    "        cluster_result = sklearn.cluster.AgglomerativeClustering(n_clusters=3).fit(cluster_data)\n",
    "        img_class = cluster_result.labels_\n",
    "        img_class[np.where(img_class==[0])]=[3]\n",
    "        img_class.reshape(1,-1)\n",
    "        for i,j in enumerate(data_index):\n",
    "            img_copy[np.where(img_copy == [j])] = img_class[i]\n",
    "        cv2.imwrite(os.path.join(save_file,name),img_copy)\n",
    "\n",
    "img_file  = r'D:\\software\\Code\\code-file\\Preprocess\\img_test2\\3_single_img\\2\\Lab\\b_channel'\n",
    "save_file = r'D:\\software\\Code\\code-file\\Preprocess\\img_test2\\4_index_map\\2_single\\Lab\\b_channel'\n",
    "img_count_pixel(img_file,save_file)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 像素总数进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_sum(input_file,save_file,nnumbe_class=5):\n",
    "    if not os.path.exists(save_file):\n",
    "        os.makedirs(save_file)\n",
    "    #创建Dataframe字典\n",
    "    df_dict = {}\n",
    "    for name in tqdm.tqdm(os.listdir(input_file)):\n",
    "        img_path = os.path.join(input_file,name)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        img_list = []\n",
    "        for i in range(256):  \n",
    "            img_list.append(np.sum(img==i))\n",
    "        #保存到字典\n",
    "        df_dict[str(name.split('.')[0])] = img_list \n",
    "    #使用字典创建DataFrame\n",
    "    df=pd.DataFrame(df_dict)\n",
    "    #是否统计总值\n",
    "    df['all'] = df.apply(lambda x:x.sum(),axis =1)\n",
    "    data = df['all']\n",
    "    data = data.drop([0])\n",
    "    data = data[~(data.isin([0]))]\n",
    "    data = data.dropna(axis=0,how='any')\n",
    "    data = data.astype(int)\n",
    "    data_index = np.array(data.index)\n",
    "    # 由于几个特征的量纲差距很大，聚类前必须进行归一化\n",
    "    cluster_data = preprocessing.scale(data)\n",
    "    # data数据进行归一化\n",
    "    cluster_data = cluster_data.reshape(-1,1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    cluster_data = min_max_scaler.fit_transform(cluster_data)\n",
    "    cluster_result = sklearn.cluster.AgglomerativeClustering(n_clusters=nnumbe_class).fit(cluster_data)\n",
    "    img_class = cluster_result.labels_\n",
    "    img_class[np.where(img_class==[0])]=[nnumbe_class]\n",
    "    img_class.reshape(1,-1)\n",
    "    for name in tqdm.tqdm(os.listdir(input_file)):\n",
    "        img_path = os.path.join(input_file,name)\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        for i,j in enumerate(data_index):\n",
    "            img[np.where(img == [j])] = img_class[i]\n",
    "        cv2.imwrite(os.path.join(save_file,name),img)\n",
    "\n",
    "\n",
    "input_file = r'D:\\31890\\Pictures\\image\\Root_senescence\\channel_image\\2\\hsv\\s_channel'\n",
    "save_file = r'D:\\31890\\Pictures\\image\\Root_senescence\\clustering_image\\2\\hsv\\s_channel'\n",
    "pixel_sum(input_file,save_file)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单通道位置像素聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单通道位置聚类的索引图的制作\n",
    "def Color_Indexes(input_file,save_file):\n",
    "    if not os.path.exists(save_file):\n",
    "                os.makedirs(save_file)\n",
    "    '''     input_file:单通道输入图片\n",
    "            save_file:保存图片的路径   '''\n",
    "\n",
    "    for img_name in tqdm.tqdm(os.listdir(input_file)):\n",
    "            image_path = os.path.join(input_file,img_name)\n",
    "            img_copy = 0\n",
    "            #单通道读取图片\n",
    "            img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "            img_copy = img\n",
    "            #提取非0元素进行聚类数据\n",
    "            tmp = img_copy[img_copy != [0]]\n",
    "            #数据整理\n",
    "            tmp = tmp.reshape(-1,1)\n",
    "            #数据归一化(对非0数据无法进行聚类)\n",
    "            min_max_scaler = preprocessing.MinMaxScaler()\n",
    "            cluster_data = min_max_scaler.fit_transform(tmp)\n",
    "            #聚类\n",
    "            #MiniBatchKMeans适用于数据较大\n",
    "            cluster_result = sklearn.cluster.MiniBatchKMeans(n_clusters=3,batch_size=4096,n_init=10).fit(cluster_data)\n",
    "            #聚类结果\n",
    "            res = cluster_result.labels_\n",
    "            #替换聚类结果中的0元素\n",
    "            res[np.where(res==[0])]=[3]\n",
    "            img_copy[np.where(img_copy != [0])] = res\n",
    "\n",
    "            #保存路径\n",
    "            save_path = os.path.join(save_file,img_name)\n",
    "            cv2.imwrite(save_path,img_copy)\n",
    "\n",
    "input_file = r'D:\\software\\Code\\code-file\\Preprocess\\img_test2\\3_single_img\\2\\Lab\\L_channel'     \n",
    "save_file = r'D:\\software\\Code\\code-file\\Preprocess\\img_test2\\4_index_map\\2_position\\Lab\\L_channel'       \n",
    "Color_Indexes(input_file,save_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对像素总和聚类\n",
    "def cluster_pixel(xlsx):\n",
    "    df_ = pd.read_excel(xlsx,index_col=0)\n",
    "    #读取总和像素\n",
    "    data = df_['all'].astype(int)\n",
    "\n",
    "    #丢弃掉0行和无像素值的行\n",
    "    data = data.drop([0])\n",
    "    data = data[~(data.isin([0]))]\n",
    "    data = data.dropna(axis=0,how='any')\n",
    "    data = data.astype(int)\n",
    "    data = data.rename('0')\n",
    "\n",
    "    #获取行索引\n",
    "    index_list= data.index.tolist()\n",
    "    # 由于几个特征的量纲差距很大，聚类前必须进行归一化\n",
    "    cluster_data = preprocessing.scale(data)\n",
    "    # data数据进行归一化\n",
    "    cluster_data = cluster_data.reshape(-1,1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    cluster_data = min_max_scaler.fit_transform(cluster_data)\n",
    "    #聚类\n",
    "    # cluster_result = AgglomerativeClustering(n_clusters=8).fit(cluster_data)\n",
    "    # # cluster_result = OPTICS(min_samples=6).fit(cluster_data)\n",
    "    # # cluster_result = SpectralClustering(n_clusters=8,\n",
    "    # #     assign_labels='discretize',\n",
    "    # #     random_state=0).fit(cluster_data)\n",
    "    # # cluster_result = KMeans(n_clusters=6, ).fit(cluster_data)\n",
    "    # # 将原数据和聚类结果输出excel\n",
    "    # cluster_dict = {'cluster':cluster_result.labels_}\n",
    "    # df_cluster = pd.DataFrame(cluster_dict,index=index_list)\n",
    "    # df_result = pd.concat([df_,df_cluster],axis=1)\n",
    "    # df_result = df_result.fillna(0).astype(int)\n",
    "    # df_result.to_excel(r'D:\\SoftWare\\Code\\Code-file\\Preprocess\\4.xlsx')\n",
    "    \n",
    "xlsx_path =r'D:\\SoftWare\\Code\\Code-file\\Preprocess\\3_image_test\\4_xlsx_file\\2\\BGR\\B_channel.xlsx'\n",
    "cluster_pixel(xlsx_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sk超像素"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "\n",
    "def Superpixel_segmentation(image_array,n_class):\n",
    "    segments = slic(img_as_float(image_array), n_segments=n_class, sigma=10)\n",
    "    result = mark_boundaries(image_array,segments)*255\n",
    "    return result\n",
    "\n",
    "def Superpixel_averaging(image_array,n_class):\n",
    "    segments = slic(img_as_float(image_array), n_segments=n_class, sigma=10)\n",
    "    seg_class = segments.max()\n",
    "    color_array = np.zeros((seg_class,3))\n",
    "    for i in range(seg_class):\n",
    "        class_array = image_array[segments==i+1]\n",
    "        color_array[i] = np.mean(class_array,axis=0)\n",
    "    color_array = color_array.astype(np.int32)\n",
    "    result = color_array[(segments-1).flatten()]\n",
    "    result = result.reshape(image_array.shape)\n",
    "    return result\n",
    "\n",
    "#单张图像\n",
    "image_path = r\"D:\\software\\Code\\code-file\\pytorch-template\\test\\cmask.png\"\n",
    "image_array = cv2.imread(image_path)\n",
    "image_array = cv2.cvtColor(image_array,cv2.COLOR_BGR2RGB)\n",
    "result = Superpixel_segmentation(image_array,900)\n",
    "result = cv2.cvtColor(result,cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(r'D:\\software\\Code\\code-file\\pytorch-template\\test\\cmask_sub.png',result)\n",
    "\n",
    "# #系列图像\n",
    "# image_file = r\"D:\\31890\\Pictures\\image\\Root_senescence\\4_egnet_pre_result(cv2)\\split\\no-taproot_Cmask_Splicing\\2\"\n",
    "# save_file = r\"D:\\31890\\Pictures\\image\\Root_senescence\\4_egnet_pre_result(cv2)\\split\\no-taproot_Cmask_Splicing_Superpixel\\2\"\n",
    "# if not os.path.exists(save_file):\n",
    "#     os.makedirs(save_file)\n",
    "# for name in tqdm.tqdm(os.listdir(image_file)):\n",
    "#     image_path = os.path.join(image_file,name)\n",
    "#     save_path = os.path.join(save_file,name.split('.')[0]+\".png\")\n",
    "#     image_array = cv2.imread(image_path)\n",
    "#     image_array = cv2.cvtColor(image_array,cv2.COLOR_BGR2RGB)\n",
    "#     result= Superpixel_averaging(image_array,n_class=900)\n",
    "#     cv2.imwrite(save_path,result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time # 用于计算运行时间\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from matplotlib import offsetbox # 定义图形box的格式\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection) \n",
    "\n",
    "#加载手写数字数据集\n",
    "digits = datasets.load_digits(n_class=6)\n",
    "#手写图\n",
    "X = digits.data\n",
    "#类别\n",
    "y = digits.target\n",
    "\n",
    "# 首先定义函数画出二维空间中的样本点，输入参数：1.降维后的数据；2.图片标题\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min) # 对每一个维度进行0-1归一化，注意此时X只有两个维度\n",
    "    \n",
    "    plt.figure(figsize= (6,6)) # 设置整个图形大小\n",
    "    ax = plt.subplot(111)\n",
    "    colors = ['#5dbe80','#2d9ed8','#a290c4','#efab40','#eb4e4f','#929591']\n",
    "    \n",
    "    # 画出样本点\n",
    "    for i in range(X.shape[0]): # 每一行代表一个样本\n",
    "        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
    "                 #color=plt.cm.Set1(y[i] / 10.),\n",
    "                 color=colors[y[i]],\n",
    "                 fontdict={'weight': 'bold', 'size': 9})  # 在样本点所在位置画出样本点的数字标签\n",
    "    \n",
    "    # 在样本点上画出缩略图，并保证缩略图够稀疏不至于相互覆盖\n",
    "    # 只有matplotlib 1.0版本以上，offsetbox才有'AnnotationBbox'，所以需要先判断是否有这个功能\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'): \n",
    "        shown_images = np.array([[1., 1.]])  # 假设最开始出现的缩略图在(1,1)位置上\n",
    "        for i in range(digits.data.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1) # 算出样本点与所有展示过的图片（shown_images）的距离\n",
    "            if np.min(dist) < 4e-3: # 若最小的距离小于4e-3，即存在有两个样本点靠的很近的情况，则通过continue跳过展示该数字图片缩略图\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]] # 展示缩略图的样本点通过纵向拼接加入到shown_images矩阵中\n",
    "            \n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "            \n",
    "    plt.xticks([]), plt.yticks([]) # 不显示横纵坐标刻度\n",
    "    if title is not None: \n",
    "        plt.title(title) \n",
    "    plt.show()\n",
    "\n",
    "t0 = time()\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "plot_embedding(X_pca,\n",
    "               \"Principal Components projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "print (pca.explained_variance_ratio_) # 每一个成分对原数据的方差解释了百分之多少"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根系主成分分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from time import time # 用于计算运行时间\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2,os,tqdm\n",
    "from matplotlib import offsetbox # 定义图形box的格式\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection) \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "image_file = r'D:\\31890\\Desktop\\tranformer\\senescence\\shuailao_re'\n",
    "def get_data(image_file):\n",
    "    img_name_list = []\n",
    "    i=0\n",
    "    for name in tqdm.tqdm(os.listdir(image_file)):\n",
    "        \n",
    "        image_path = os.path.join(image_file,name)\n",
    "        img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        img_flatten = img.flatten()\n",
    "        img_name_list.append(name)\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        img_flatten = np.expand_dims(img_flatten,axis=0)\n",
    "        if i==0:\n",
    "            # img_group = img\n",
    "            img_flatten_group = img_flatten\n",
    "        else:\n",
    "            # img_group = np.concatenate((img_group, img), axis = 0)\n",
    "            img_flatten_group = np.concatenate((img_flatten_group, img_flatten), axis = 0) \n",
    "        i+=1\n",
    "    # return img_group, img_flatten_group, img_name_list\n",
    "    return img_flatten_group, img_name_list\n",
    "\n",
    "\n",
    "img_flatten_group ,img_name_list =get_data(image_file)\n",
    "# print(img_group.shape)\n",
    "# print(img_flatten_group.shape)\n",
    "\n",
    "t0 = time()\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(img_flatten_group.astype(np.float32))\n",
    "\n",
    "cluster_result = sklearn.cluster.AgglomerativeClustering(n_clusters=10).fit(X_pca)\n",
    "img_class = cluster_result.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(X, title=None):              ####—————— 首先定义函数画出二维空间中的样本点，输入参数：1.降维后的数据；2.图片标题\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)           ####—————— 对每一个维度进行0-1归一化，注意此时X只有两个维度\n",
    "    \n",
    "    plt.figure(figsize= (18,18))                ####—————— 设置整个图形大小\n",
    "    ax = plt.subplot(111)\n",
    "    colors = [  '#FF0000','#FF8C00','#FFE4B5','#9ACD32','#00FF00',      ####—————— 设置颜色矩阵\n",
    "                '#00FFFF','#4169E1','#9400D3','#FF00FF','#708090']\n",
    "    \n",
    "    # 画出样本点\n",
    "    plt.scatter(X[:, 0], X[:, 1])                                       ####—————— 画出样本点\n",
    "\n",
    "    for i in range(X.shape[0]):                                         ####—————— 每一行代表一个样本\n",
    "        plt.text(X[i, 0]+0.01, X[i, 1], img_name_list[i],\n",
    "                 #color=plt.cm.Set1(y[i] / 10.),\n",
    "                 color=colors[img_class[i]],\n",
    "                #  horizontalalignment=\"left\",\n",
    "                 fontdict={'weight': 'bold', 'size': 12})               ####—————— 在样本点所在位置画出样本点的数字标签\n",
    "    \n",
    "    # 在样本点上画出缩略图，并保证缩略图够稀疏不至于相互覆盖\n",
    "    # 只有matplotlib 1.0版本以上，offsetbox才有'AnnotationBbox'，所以需要先判断是否有这个功能\n",
    "    # if hasattr(offsetbox, 'AnnotationBbox'): \n",
    "    #     shown_images = np.array([[1., 1.]])  # 假设最开始出现的缩略图在(1,1)位置上\n",
    "    #     for i in range(img_flatten_group.shape[0]):\n",
    "    #         dist = np.sum((X[i] - shown_images) ** 2, 1) # 算出样本点与所有展示过的图片（shown_images）的距离\n",
    "    #         if np.min(dist) < 4e-3: # 若最小的距离小于4e-3，即存在有两个样本点靠的很近的情况，则通过continue跳过展示该数字图片缩略图\n",
    "    #             continue\n",
    "    #         shown_images = np.r_[shown_images, [X[i]]] # 展示缩略图的样本点通过纵向拼接加入到shown_images矩阵中\n",
    "    #         plt_image = cv2.resize(img_group[i],(12,15))\n",
    "    #         imagebox = offsetbox.AnnotationBbox(\n",
    "    #             offsetbox.OffsetImage(plt_image, cmap=plt.cm.gray_r),\n",
    "    #             X[i])\n",
    "    #         ax.add_artist(imagebox)\n",
    "    \n",
    "    plt.xlim(-0.1,1.1)                              ####—————— 设置x轴的刻度限制\n",
    "    plt.ylim(-0.1,1.1)                              ####—————— 设置y轴的刻度限制\n",
    "\n",
    "    y_major_locator=MultipleLocator(0.1)            ####—————— 把y轴的刻度间隔设置为10，并存在变量里\n",
    "\n",
    "    ax=plt.gca()                                    ####——————  ax为两条坐标轴的实例\n",
    "    ax.yaxis.set_major_locator(y_major_locator)\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])                  ####—————— 不显示横纵坐标刻度\n",
    "    if title is not None: \n",
    "        plt.title(title)                            ####—————— 设置图标的标题\n",
    "    plt.savefig(r\"D:\\31890\\Desktop\\senescence\\cluster.svg\",dpi=200, bbox_inches='tight')    \n",
    "    plt.show()\n",
    "    \n",
    "plot_embedding(X_pca,\n",
    "               \"Principal Components projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "print (pca.explained_variance_ratio_)               ####——————  每一个成分对原数据的方差解释了百分之多少"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('seg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d6e131864ec247051f61f44c3669fa89bfc29c37f428584647267d767cbe399"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
