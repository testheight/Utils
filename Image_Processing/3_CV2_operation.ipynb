{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,tqdm,cv2,sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "\n",
    "#取消像素限制\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV2操作"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re(i,i2,o):\n",
    "    if not os.path.exists(o):\n",
    "        os.makedirs(o)\n",
    "    for name in tqdm.tqdm(os.listdir(i)):\n",
    "        img_path = os.path.join(i,name)\n",
    "        img_path2 = os.path.join(i2,name.split('.')[0]+'.jpg')\n",
    "        save_path = os.path.join(o,name.split('.')[0]+'.jpg')\n",
    "        img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        h,w = img.shape\n",
    "        img2 = cv2.imread(img_path2)\n",
    "        img2 = cv2.resize(img2,(w,h))\n",
    "        cv2.imwrite(save_path,img2)\n",
    "\n",
    "i = r\"D:\\31890\\Desktop\\codefile\\Utils\\biaozhu\"\n",
    "i2 = r'D:\\31890\\Desktop\\codefile\\data\\Train_data\\Datasets\\senescence\\1\\o'\n",
    "o = r\"D:\\31890\\Desktop\\codefile\\Utils\\o2\"\n",
    "re(i,i2,o)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 灰度图像的滤波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_filter(img_file,filter_file):\n",
    "    '''     img_file:输入的灰度图片\n",
    "            filter_file:滤波保存的图片        '''\n",
    "    for name in tqdm.tqdm(os.listdir(img_file)):\n",
    "        img_path = os.path.join(img_file,name)\n",
    "        original_image = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "        # 均值滤波\n",
    "        img_blur=cv2.blur(original_image,(3,3))\n",
    "        save_path= os.path.join(filter_file,name.split('.')[0]+\"Mean_\"+\".png\")\n",
    "        cv2.imwrite(save_path,img_blur)\n",
    "        #方框滤波\n",
    "        img_boxFilter1 = cv2.boxFilter(original_image, -1, (5, 5), normalize=True)\n",
    "        save_path= os.path.join(filter_file,name.split('.')[0]+\"box_\"+'.png')\n",
    "        cv2.imwrite(save_path,img_boxFilter1)\n",
    "        #高斯滤波\n",
    "        img_GaussianBlur= cv2.GaussianBlur(original_image, (5, 5), 0, 0)\n",
    "        save_path= os.path.join(filter_file,name.split('.')[0]+\"Gaussian_\"+\".png\")\n",
    "        cv2.imwrite(save_path,img_GaussianBlur)\n",
    "        # 中值滤波\n",
    "        img_medianBlur = cv2.medianBlur(original_image, 5)\n",
    "        save_path= os.path.join(filter_file,name.split('.')[0]+\"median_\"+\".png\")\n",
    "        cv2.imwrite(save_path,img_medianBlur)\n",
    "        # 双边滤波\n",
    "        img_bilateralFilter=cv2.bilateralFilter(original_image,50,100,100)\n",
    "        save_path= os.path.join(filter_file,name.split('.')[0]+\"Bilateral_\"+'.png')\n",
    "        cv2.imwrite(save_path,img_bilateralFilter)\n",
    "        # 形态学滤波\n",
    "        kernel = np.random.normal(0.01,1,size=(5,5))\n",
    "        kernel = np.ones((3,3))\n",
    "        img_mo = cv2.morphologyEx(original_image,cv2.MORPH_CLOSE,kernel)\n",
    "        save_path= os.path.join(filter_file,name.split('.')[0]+\"clsoe\"+\".png\")\n",
    "        cv2.imwrite(save_path,img_mo)\n",
    "        kernel = np.ones((3,3))\n",
    "        img_mo = cv2.morphologyEx(original_image,cv2.MORPH_OPEN,kernel)\n",
    "        save_path= os.path.join(filter_file,name.split('.')[0]+\"open\"+\".png\")\n",
    "        cv2.imwrite(save_path,img_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r\"D:\\31890\\Desktop\\1\\10.jpg\"\n",
    "original_image = cv2.imread(img_path)\n",
    "# 均值滤波\n",
    "img_blur=cv2.blur(original_image,(8,8))\n",
    "# img_blur=cv2.blur(img_blur,(8,12))\n",
    "\n",
    "cv2.imwrite(r\"D:\\31890\\Desktop\\1\\10_2.jpg\",img_blur)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像去噪加图像增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Denoising_enhancement(img_file,save_path):\n",
    "    '''     img_file:输入图片的路径\n",
    "            save_path:保存图片的路径      '''\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for name in tqdm.tqdm(os.listdir(img_file)):\n",
    "        image_name = os.path.splitext(name)[0]\n",
    "        img = cv2.imread(os.path.join(img_file,name))\n",
    "        # h参数调节过滤器强度。大的h值可以完美消除噪点，但同时也可以消除图像细节，较小的h值可以保留细节但也可以保留一些噪点\n",
    "        h = 10\n",
    "        # templateWindowSize用于计算权重的模板补丁的像素大小，为奇数，默认7\n",
    "        templateWindowSize = 5\n",
    "        # searchWindowSize窗口的像素大小，用于计算给定像素的加权平均值，为奇数，默认21\n",
    "        searchWindowSize = 21\n",
    "        # dst = cv2.fastNlMeansDenoising(img, None, h, h, templateWindowSize, searchWindowSize)\n",
    "        #非局部均值滤波\n",
    "        Deno = cv2.fastNlMeansDenoising(img,None, h, templateWindowSize, searchWindowSize)\n",
    "        #高斯模糊\n",
    "        img_GaussianBlur= cv2.GaussianBlur(Deno, (5, 5), 0, 0)\n",
    "        #USM增强\n",
    "        usm = cv2.addWeighted(img,1.5,img_GaussianBlur,-0.5,0)  \n",
    "        #保存\n",
    "        result_path = os.path.join(save_path,image_name + \".png\")\n",
    "        cv2.imwrite(result_path,usm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2show(image,name=\"image1\",h=1000,w=900):\n",
    "    cv2.namedWindow(str(name), cv2.WINDOW_KEEPRATIO)\n",
    "    # WINDOW_NORMAL\t用户能够调节窗口大小\n",
    "    # WINDOW_AUTOSIZE\t根据图像大小显示窗口，大小固定\n",
    "    # WINDOW_FREERATIO\t调整图像。不考虑其比例\n",
    "    # WINDOW_KEEPRATIO\t保持图像比例\n",
    "    cv2.resizeWindow(str(name), w ,h)\n",
    "    cv2.imshow(str(name),image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    " \n",
    "# Scharr算子实现梯度计算\n",
    "def Scharr_demo(image_array):\n",
    "\n",
    "    # cv2.namedWindow('image_gradient-x', 0)\n",
    "    # cv2.resizeWindow('image_gradient-x', 900 ,1000)\n",
    "    # cv2.namedWindow('image_gradient-y', 0)\n",
    "    # cv2.resizeWindow('image_gradient-y', 900 ,1000)    \n",
    "    # cv2.namedWindow('iamg_', 0)\n",
    "    # cv2.resizeWindow('iamg_', 900 ,1000)\n",
    "    # cv2.namedWindow('img_GaussianBlur', 0)\n",
    "    # cv2.resizeWindow('img_GaussianBlur', 900 ,1000)\n",
    "    # cv2.namedWindow('image_gradient', 0)\n",
    "    # cv2.resizeWindow('image_gradient', 900 ,1000)\n",
    "\n",
    "    # x 方向梯度\n",
    "    image_grad_x = cv2.Scharr(image_array, cv2.CV_32F, 1, 0)\n",
    "\n",
    "    # y 方向梯度\n",
    "    image_grad_y = cv2.Scharr(image_array, cv2.CV_32F, 0, 1)\n",
    "\n",
    "    # 分别求绝对值并转化为8位的图像上，这样做方便显示\n",
    "    image_gradx = cv2.convertScaleAbs(image_grad_x) \n",
    "    image_grady = cv2.convertScaleAbs(image_grad_y)\n",
    "\n",
    "    # 显示两个方向图像\n",
    "    # cv2.imshow(\"image_gradient-x\", image_gradx)\n",
    "    # cv2.imshow(\"image_gradient-y\", image_grady)\n",
    "    \n",
    "    #两个方向梯度的叠加，权重各自一半\n",
    "    # image_gradxy = cv2.addWeighted(image_gradx, 0.5, image_grady, 0.5, 0)\n",
    "    # cv2.imshow(\"image_gradient\", image_gradxy)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return image_grady\n",
    "    \n",
    "\n",
    "image_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test\\1.png'\n",
    "save_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test\\2.png'\n",
    "Scharr_demo(image_path,save_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 腐蚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test2\\1_grad_y.png'\n",
    "save_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test2\\1_grad_y_erode2.png'\n",
    "\n",
    "def erode_demo(image_array):\n",
    "    # 创建矩形结构元\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,2))\n",
    "    # 腐蚀图像\n",
    "    img_erode = cv2.erode(image_array, kernel,iterations=2)\n",
    "    return img_erode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 膨胀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'D:\\software\\code\\code-file\\image\\test\\02-20190619-1200-0538_3_13.png'\n",
    "def dilate_demo(image_path,save_path):\n",
    "    img_src = cv2.imread(image_path, 0)\n",
    "    # 创建结构元\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,8))\n",
    "    # 腐蚀图像,\n",
    "    img_dilate = cv2.dilate(img_src, kernel,iterations=5)\n",
    "    # cv2.namedWindow('img_src', 0)\n",
    "    # cv2.resizeWindow('img_src', 200, 200)\n",
    "    # cv2.imshow(\"img_src\",img_src)\n",
    "    cv2.imwrite(save_path,img_dilate)\n",
    "\n",
    "    # cv2.waitKey(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 形态学操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,tqdm,cv2,sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "\n",
    "#取消像素限制\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "image_path = r\"D:\\31890\\Desktop\\1\\200.jpg\"\n",
    "save_path = r\"D:\\31890\\Desktop\\1\\200_1.jpg\"\n",
    "\n",
    "def morphologyEx_demo(image_path,save_path):\n",
    "    iamge = cv2.imread(image_path)\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_CLOSE,(2,2))#3,40\n",
    "    kernel = np.ones((4,4),np.uint8)\n",
    "\n",
    "    # MORPH_ERODE 腐蚀 erode\n",
    "    # MORPH_DILATE 膨胀 dilate\n",
    "    # MORPH_OPEN 开运算（先腐蚀后膨胀）\n",
    "    # MORPH_CLOSE 闭运算（先膨胀后腐蚀）\n",
    "    # MORPH_GRADIENT 形态学梯度\n",
    "    # MORPH_TOPHAT 顶帽运算\n",
    "    # MORPH_BLACKHAT 底帽运算\n",
    "    \n",
    "    result  = cv2.morphologyEx(iamge,cv2.MORPH_CLOSE,kernel,iterations=2)\n",
    "    cv2.imwrite(save_path,result)\n",
    "\n",
    "morphologyEx_demo(image_path,save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 滑条操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_src = cv2.imread(r\"D:\\software\\Code\\code-file\\image\\Root_senescence\\egnet_pre_cv2\\open\\2\\02-20190619-1200-0538.png\", 0)\n",
    "\n",
    "def nothing(*args):\n",
    "    pass\n",
    "r, i = 1, 1\n",
    "max_r, max_i = 20, 20\n",
    "\n",
    "cv2.namedWindow('morphology', 0)\n",
    "cv2.resizeWindow('morphology', 900 ,1000)\n",
    "cv2.createTrackbar('r', 'morphology', r, max_r, nothing)\n",
    "cv2.createTrackbar('i', 'morphology', i, max_i, nothing)\n",
    "\n",
    "while True:\n",
    "    r = cv2.getTrackbarPos('r', 'morphology')\n",
    "    i = cv2.getTrackbarPos('i', 'morphology')\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2*r+1, 2*r+1))\n",
    "    # 形态学操作\n",
    "    # MORPH_ERODE 腐蚀 erode\n",
    "    # MORPH_DILATE 膨胀 dilate\n",
    "    # MORPH_OPEN 开运算（先腐蚀后膨胀）\n",
    "    # MORPH_CLOSE 闭运算（先膨胀后腐蚀）\n",
    "    # MORPH_GRADIENT 形态学梯度\n",
    "    # MORPH_TOPHAT 顶帽运算\n",
    "    # MORPH_BLACKHAT 底帽运算\n",
    "    img_erode = cv2.morphologyEx(img_src,cv2.MORPH_OPEN, kernel, iterations=i)\n",
    "    cv2.imshow(\"morphology\", img_erode)\n",
    "    cv2.waitKey(10)\n",
    "    # cv2.imwrite(r'D:\\software\\Code\\code-file\\pytorch-template\\test2\\2_ERODE.png',img_erode)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 滑动条的回调函数，获取滑动条位置处的值\n",
    "def empty(a):\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"TrackBars\")\n",
    "    # print(h_min, h_max, s_min, s_max, v_min, v_max)\n",
    "    return h_min, h_max, s_min, s_max, v_min, v_max\n",
    "\n",
    "path = r'D:\\software\\Code\\code-file\\pytorch-template\\test\\cmask_sub.png'\n",
    "# 创建一个窗口，放置6个滑动条\n",
    "cv2.namedWindow(\"TrackBars\",0)\n",
    "cv2.resizeWindow(\"TrackBars\",320,240)\n",
    "cv2.createTrackbar(\"Hue Min\",\"TrackBars\",0,179,empty)\n",
    "cv2.createTrackbar(\"Hue Max\",\"TrackBars\",19,179,empty)\n",
    "cv2.createTrackbar(\"Sat Min\",\"TrackBars\",110,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"TrackBars\",240,255,empty)\n",
    "cv2.createTrackbar(\"Val Min\",\"TrackBars\",153,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"TrackBars\",255,255,empty)\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread(path)\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    # 调用回调函数，获取滑动条的值\n",
    "    h_min,h_max,s_min,s_max,v_min,v_max = empty(0)\n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    # 获得指定颜色范围内的掩码\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    # 对原图图像进行按位与的操作，掩码区域保留\n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask)\n",
    "   \n",
    "    # cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Result\", imgResult)\n",
    "    \n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像相减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test\\1_b.png'\n",
    "image2_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test\\3_2.png'\n",
    "save_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test\\4.png'\n",
    "\n",
    "def subtract_demo(image1_array,image2_array):\n",
    "\n",
    "    image = image1_array - image2_array\n",
    "\n",
    "    return image\n",
    "\n",
    "subtract_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 遍历相减\n",
    "\n",
    "def ergodic_func(image1_path,target_path,save_path):\n",
    "    image1 = cv2.imread(image1_path,cv2.IMREAD_GRAYSCALE)\n",
    "    target = cv2.imread(target_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    h,w = image1.shape\n",
    "    for x in range(w):\n",
    "        for y in range (w):\n",
    "            if image1[x,y] !=  0:\n",
    "                target[x,y]=0\n",
    "    \n",
    "    cv2.imwrite(save_path,target)\n",
    "\n",
    "\n",
    "image1_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test2\\1_grad_y_ERODE.png'\n",
    "target_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test2\\1_threshold.png'\n",
    "save_path = r'D:\\software\\Code\\code-file\\pytorch-template\\test2\\2.png'\n",
    "ergodic_func(image1_path,target_path,save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "transform =A.Compose([\n",
    "    A.Normalize(mean=[0.4754358, 0.35509014, 0.282971],std=[0.16318515, 0.15616792, 0.15164918],max_pixel_value=255.0, always_apply=False)])\n",
    "\n",
    "image_file = r'D:\\31890\\Pictures\\image\\Root_senescence\\split_image_o\\2'\n",
    "save_file = r'D:\\31890\\Pictures\\image\\Root_senescence\\split_image_norm\\2'\n",
    "if not os.path.exists(save_file):\n",
    "    os.makedirs(save_file)\n",
    "for name in os.listdir(image_file):\n",
    "    iamge_Path = os.path.join(image_file,name)\n",
    "    save_path  = os.path.join(save_file,name)\n",
    "    image = cv2.imread(iamge_Path)\n",
    "    transformed = transform(image=image)\n",
    "    transformed_image = transformed['image']\n",
    "    # cv2.imshow(\"a\",transformed_image)\n",
    "    print(transformed_image)\n",
    "    # cv2.imshow(\"b\",transformed_mask)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imwrite(save_path,transformed_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alpha通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r'D:\\software\\code\\code-file\\T\\image\\mydata\\my_data\\imgs\\train\\1_4_6.jpg')\n",
    "\n",
    "        # 使用cv.merge()函数添加alpha通道\n",
    "zeros = np.ones(img.shape[:2], dtype=img.dtype) *255\n",
    "result_BGR_alpha = cv2.merge([img, zeros])\n",
    "print('原图的通道数为：{}'.format(img.shape[2]))\n",
    "print('处理后的通道数为：{}'.format(result_BGR_alpha.shape[2]))\n",
    "\n",
    "cv2.imwrite(r'D:\\31890\\Desktop\\1\\1.png',result_BGR_alpha)\n",
    "\n",
    "#通道提取\n",
    "cv2.imwrite(r'D:\\31890\\Desktop\\1\\1.png',result_BGR_alpha)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BGR单通道的直方图\n",
    "def BGR_signal_channel_hist_process(BGR_signal_file_one_channel,model_pre_file,BGR_Hist_image_K_mean):\n",
    "    R_channel = os.path.join(BGR_signal_file_one_channel, \"RGB_channel\", \"R_channel\")\n",
    "    G_channel = os.path.join(BGR_signal_file_one_channel, \"RGB_channel\", \"G_channel\")\n",
    "    B_channel = os.path.join(BGR_signal_file_one_channel, \"RGB_channel\", \"B_channel\")\n",
    "\n",
    "    if not os.path.exists(BGR_Hist_image_K_mean):\n",
    "        os.makedirs(BGR_Hist_image_K_mean)\n",
    "\n",
    "    for name in tqdm.tqdm(os.listdir(R_channel)):\n",
    "        R_channel_path = os.path.join(R_channel, name)\n",
    "        G_channel_path = os.path.join(G_channel, name)\n",
    "        B_channel_path = os.path.join(B_channel, name)\n",
    "        mask_path = os.path.join(model_pre_file,name)\n",
    "        save_path = os.path.join(BGR_Hist_image_K_mean,name)\n",
    "        R_img = cv2.imread(R_channel_path,cv2.IMREAD_GRAYSCALE)\n",
    "        G_img = cv2.imread(G_channel_path, cv2.IMREAD_GRAYSCALE)\n",
    "        B_img = cv2.imread(B_channel_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)\n",
    "        retVal, mask = cv2.threshold(mask, 45, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "        R_hist = cv2.calcHist([R_img], [0], mask, [256], [0, 256])\n",
    "        G_hist = cv2.calcHist([G_img], [0], mask, [256], [0, 256])\n",
    "        B_hist = cv2.calcHist([B_img], [0], mask, [256], [0, 256])\n",
    "\n",
    "        plt.figure(figsize=(6,7))\n",
    "        ax = plt.gca()\n",
    "        y_major_locator = MultipleLocator(1000)\n",
    "        ax.yaxis.set_major_locator(y_major_locator)\n",
    "        plt.xlim(0, 256)\n",
    "        plt.ylim(0, 9000)\n",
    "        plt.xlabel('Pixels')\n",
    "        plt.ylabel('Numbers')\n",
    "\n",
    "        plt.plot(R_hist, label='red-channel', color='red')\n",
    "        plt.plot(G_hist, label='green-channel', color='green')\n",
    "        plt.plot(B_hist, label='blue-channel', color='blue')\n",
    "        plt.title('day'+str((name.split('_')[0]).split('-')[-1]))\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(save_path)\n",
    "        plt.close('all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像叠加分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,glob,os,tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def fun(ground_true,file_list,o):\n",
    "    if not os.path.exists(o):\n",
    "        os.makedirs(o)\n",
    "    for p in tqdm.tqdm(file_list):\n",
    "        for name in tqdm.tqdm(os.listdir(ground_true)):\n",
    "            img1_p = os.path.join(ground_true,name)\n",
    "            img2_P = os.path.join(p,name)\n",
    "            img1 = cv2.imread(img1_p,cv2.IMREAD_GRAYSCALE)\n",
    "            img2 = cv2.imread(img2_P,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            img1 = np.where(img1!=0,1,0)\n",
    "            img2 = np.where(img2!=0,2,0)\n",
    "\n",
    "            imgs_union = img1+img2\n",
    "\n",
    "            imgs_union = Image.fromarray(imgs_union)\n",
    "\n",
    "            imgs_union = imgs_union.convert('L')\n",
    "                    #调色板\n",
    "            palette = [0, 0, 0,0, 255, 0, 255, 0, 0,255,255,255]  #\n",
    "                        #0 背景 1 标注有，预测没有 2标注没有，预测有 3 两者交集\n",
    "                    #着色\n",
    "            imgs_union.putpalette(palette)\n",
    "            save_path = os.path.join(o,name.split('.')[0]+'_'+p.split('\\\\')[-1]+'.png')\n",
    "            imgs_union.save(save_path)\n",
    "\n",
    "file_list  =glob.glob(r\"D:\\31890\\Desktop\\tranformer\\model_compare\\pred\\*\")\n",
    "ground_true = r\"D:\\31890\\Desktop\\tranformer\\model_compare\\label\"\n",
    "o = r\"D:\\31890\\Desktop\\tranformer\\model_compare\\fenlei\"\n",
    "fun(ground_true,file_list,o)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像的连通域操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# 读入图片\n",
    "img = cv2.imread(\"001.jpg\")\n",
    "# 中值滤波，去噪\n",
    "img = cv2.medianBlur(img, 3)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.namedWindow('original', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('original', gray)\n",
    " \n",
    "# 阈值分割得到二值化图片\n",
    "ret, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    " \n",
    "# 膨胀操作\n",
    "kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "bin_clo = cv2.dilate(binary, kernel2, iterations=2)\n",
    " \n",
    "# 连通域分析\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(bin_clo, connectivity=8)\n",
    " \n",
    "# 查看各个返回值\n",
    "# 连通域数量\n",
    "print('num_labels = ',num_labels)\n",
    "# 连通域的信息：对应各个轮廓的x、y、width、height和面积\n",
    "print('stats = ',stats)\n",
    "# 连通域的中心点\n",
    "print('centroids = ',centroids)\n",
    "# 每一个像素的标签1、2、3.。。，同一个连通域的标签是一致的\n",
    "print('labels = ',labels)\n",
    " \n",
    "# 不同的连通域赋予不同的颜色\n",
    "output = np.zeros((img.shape[0], img.shape[1], 3), np.uint8)\n",
    "for i in range(1, num_labels):\n",
    " \n",
    "    mask = labels == i\n",
    "    output[:, :, 0][mask] = np.random.randint(0, 255)\n",
    "    output[:, :, 1][mask] = np.random.randint(0, 255)\n",
    "    output[:, :, 2][mask] = np.random.randint(0, 255)\n",
    "cv2.imshow('oginal', output)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv像素操作"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 像素值替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_replacement(image_file,save_file):\n",
    "    for name in tqdm.tqdm(os.listdir(image_file)):\n",
    "        save_path = os.path.join(save_file,name)\n",
    "        image_path = os.path.join(image_file,name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        h,w,c = img.shape\n",
    "        b = np.empty([h,w])\n",
    "        for x in range(h):\n",
    "            for y in range(w):\n",
    "                #黑色[0,0,0]\n",
    "                if (img[x,y]==[0,0,0]).all():\n",
    "                    continue\n",
    "                #红色[255,0,0]\n",
    "                elif (img[x,y]==[255,0,0]).all():\n",
    "                    b[x,y]=2\n",
    "                #绿色[0,255,0]\n",
    "                elif (img[x,y,]==[0,255,0]).all():\n",
    "                    b[x,y]=3\n",
    "                else:\n",
    "                    b[x,y]=1\n",
    "        cv2.imwrite(save_path,b)\n",
    "\n",
    "def pixel_grayscale(image_file,save_file):\n",
    "    if not os.path.exists(save_file):\n",
    "        os.makedirs(save_file)\n",
    "    for name in tqdm.tqdm(os.listdir(image_file)):\n",
    "        save_path = os.path.join(save_file,name)\n",
    "        img = cv2.imread(os.path.join(image_file,name),cv2.IMREAD_GRAYSCALE)\n",
    "        h,w = img.shape\n",
    "        b = np.empty([h,w])\n",
    "        for x in range(h):\n",
    "            for y in range(w):\n",
    "                #黑色[0,0,0]\n",
    "                if (img[x,y]==0).all():\n",
    "                    continue\n",
    "                #红色[255,0,0]\n",
    "                elif (img[x,y]==250).all():\n",
    "                    b[x,y]=1\n",
    "                #绿色[0,255,0]\n",
    "                elif (img[x,y,]==76).all():\n",
    "                    b[x,y]=2\n",
    "                else:\n",
    "                    b[x,y]=3\n",
    "        cv2.imwrite(save_path,b)\n",
    "image_file = r'D:\\31890\\Desktop\\codefile\\Utils\\biaozhuchuli'\n",
    "save_file  = r'D:\\31890\\Desktop\\codefile\\Utils\\biaozhu'\n",
    "pixel_grayscale(image_file,save_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 像素提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_replacement(image_file,death_file,live_file):\n",
    "    for name in tqdm.tqdm(os.listdir(image_file)):\n",
    "        image_path = os.path.join(image_file,name)\n",
    "        save_death = os.path.join(death_file,name)\n",
    "        save_live = os.path.join(live_file,name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        h,w,c = img.shape\n",
    "        #death\n",
    "        b = np.empty([h,w])\n",
    "        #live\n",
    "        b2 = np.empty([h,w])\n",
    "        for x in range(h):\n",
    "            for y in range(w):\n",
    "                #黑色[0,0,0]\n",
    "                if (img[x,y]==[0,0,0]).all():\n",
    "                    continue\n",
    "                #活根\n",
    "                elif (img[x,y]==[128,0,0]).all():\n",
    "                    b[x,y]=255\n",
    "                else:\n",
    "                    b2[x,y]=255\n",
    "        cv2.imwrite(save_death,b)\n",
    "        cv2.imwrite(save_live,b2)\n",
    "image_file = r'D:\\31890\\Desktop\\senescence\\senescence\\mix'\n",
    "death_file  = r'D:\\31890\\Desktop\\senescence\\senescence\\death'\n",
    "live_file = r'D:\\31890\\Desktop\\senescence\\senescence\\live'\n",
    "pixel_replacement(image_file,death_file,live_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 阈值操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold2(image_array,lower=[0,108,118],upper=[45,188,109]):\n",
    "    lower_red = np.array(lower)\n",
    "    upper_red = np.array(upper)\n",
    "    #lower_red～upper_red之间的值变成255\n",
    "    mask = cv2.inRange(image_array,lower_red,upper_red)\n",
    "    mask\n",
    "    # imgResult = cv2.bitwise_and(image_array,image_array,mask=mask)\n",
    "    # return cv2.cvtColor(imgResult,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "#单张图像\n",
    "# image_path = r'D:\\software\\code\\codefile\\T\\image\\compare_image\\splic\\result\\1.png'\n",
    "# save_path = r'D:\\software\\code\\codefile\\T\\image\\compare_image\\splic\\binary\\1.png'\n",
    "# image_array = cv2.imread(image_path)\n",
    "# result = threshold(image_array, 35, 255)\n",
    "# cv2.imwrite(save_path,result)\n",
    "\n",
    "#系列图像\n",
    "image_file = r\"D:\\software\\code\\codefile\\T\\image\\Root_senescence\\1_egnet_result\\Splicing\\mask\\2_512-64\"\n",
    "save_file  = r\"D:\\software\\code\\codefile\\T\\image\\Root_senescence\\1_egnet_result\\Splicing\\binary\\2_512-64\"\n",
    "if not os.path.exists(save_file):\n",
    "    os.makedirs(save_file)\n",
    "for name in tqdm.tqdm(os.listdir(image_file)):\n",
    "    image_path = os.path.join(image_file,name)\n",
    "    save_path = os.path.join(save_file,name)\n",
    "    image_array = cv2.imread(image_path)\n",
    "    result= threshold2(image_array, lower=[0,108,118],upper=[45,188,109])\n",
    "    cv2.imwrite(save_path,result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据阈值转换为黑白图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(img_file,save_file,lower):\n",
    "    save_file = save_file+\"_threshold\"+str(lower)\n",
    "    if not os.path.exists(save_file):\n",
    "        os.makedirs(save_file)\n",
    "    for name in tqdm.tqdm((os.listdir(img_file))):\n",
    "        single_image_path = os.path.join(img_file, name)\n",
    "        image = cv2.imread(single_image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        imagel = np.where(image>lower,255,0)\n",
    "        cv2.imwrite(os.path.join(save_file,name),imagel)\n",
    "\n",
    "i = r'D:\\31890\\Downloads\\2_512-64'\n",
    "o = r'D:\\31890\\Downloads\\2_512-64-155'\n",
    "fun(i,o,155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(img_file,save_file):\n",
    "    if not os.path.exists(save_file):\n",
    "        os.makedirs(save_file)\n",
    "    for name in tqdm.tqdm((os.listdir(img_file))):\n",
    "        single_image_path = os.path.join(img_file, name)\n",
    "        image = cv2.imread(single_image_path,cv2.IMREAD_GRAYSCALE)\n",
    "        imagel = np.where(image>0,1,0)\n",
    "        cv2.imwrite(os.path.join(save_file,name),imagel)\n",
    "\n",
    "i = r'D:\\31890\\Desktop\\my_data\\anno\\train'\n",
    "o = r'D:\\31890\\Desktop\\my_data\\anno'\n",
    "fun(i,o)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成mask图像操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,tqdm,cv2,sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "\n",
    "#取消像素限制\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "def Mask(org_img_file,mode_pre_file,out_file,color):\n",
    "    '''     org_img_file:原始图片\n",
    "            mode_pre_file:模型预测结果11\n",
    "            out_file:保存路径\n",
    "            color:颜色通道   '''\n",
    "    for name in tqdm.tqdm(os.listdir(org_img_file)):\n",
    "        image_name = os.path.splitext(name)[0]\n",
    "        image_path = os.path.join(org_img_file, name)\n",
    "        mask_path = os.path.join(mode_pre_file, image_name+'.png')\n",
    "        #cv2读取图片的方式为BGR\n",
    "      \n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        #模型预测的灰度图片\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        h,w  = mask.shape\n",
    "        image = cv2.resize(image,(w,h))\n",
    "        #模型预测图片阈值剪切\n",
    "        retVal, mask = cv2.threshold(mask, 45, 255, cv2.THRESH_TOZERO)\n",
    "        mask = np.where(mask==0,255,0).astype(np.uint8)\n",
    "        # retVal, mask = cv2.threshold(mask, 45, 255, cv2.THRESH_TOZERO)\n",
    "        #是否颜色空间转换\n",
    "        if color:\n",
    "            if color==\"BGR\":\n",
    "                if not os.path.exists(os.path.join(out_file,color)):\n",
    "                    os.makedirs(os.path.join(out_file,color))\n",
    "                color_mask = os.path.join(out_file,color,image_name+'.png')\n",
    "                image2 = cv2.bitwise_and(image, image, mask=mask) \n",
    "                cv2.imwrite(color_mask, image2)\n",
    "            elif color==\"HSV\":\n",
    "                if not os.path.exists(os.path.join(out_file,color)):\n",
    "                    os.makedirs(os.path.join(out_file,color))\n",
    "                color_mask = os.path.join(out_file,color,image_name+'.png')\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "                image2 = cv2.bitwise_and(image, image, mask=mask) \n",
    "                cv2.imwrite(color_mask, image2)\n",
    "            elif color==\"Lab\":\n",
    "                if not os.path.exists(os.path.join(out_file,color)):\n",
    "                    os.makedirs(os.path.join(out_file,color))\n",
    "                color_mask = os.path.join(out_file,color,image_name+'.png')\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "                image2 = cv2.bitwise_and(image, image, mask=mask) \n",
    "                cv2.imwrite(color_mask, image2) \n",
    "i = r\"D:\\31890\\Desktop\\tranformer\\senescence\\in-situ2\"\n",
    "m = r\"D:\\31890\\Desktop\\codefile\\result\\Train_data\\Datasets\\GAN\\completion_label\"\n",
    "o = r\"D:\\31890\\Desktop\\codefile\\result\\Train_data\\Datasets\\GAN\\cimage\"\n",
    "Mask(i,m,o,\"BGR\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 索引图着色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster \n",
    "import pandas as pd\n",
    "#索引图制作RGB像素图\n",
    "def colormap(input_file,save_file):\n",
    "    '''     input_file:索引图输入图片\n",
    "            save_file:RGB图片的路径   '''\n",
    "    if not os.path.exists(save_file):\n",
    "        os.makedirs(save_file)\n",
    "    for img_name in tqdm.tqdm(os.listdir(input_file)):\n",
    "        img_path = os.path.join(input_file,img_name)\n",
    "        img = Image.open(img_path)\n",
    "        img.convert('L')\n",
    "        #调色板\n",
    "        palette = [0, 0, 0,0, 128, 0, 128, 128, 0]\n",
    "        # palette = [0, 0, 0, 128, 0, 0,0, 128, 0, 128, 128, 0,\n",
    "        #         0, 0, 128,]\n",
    "                # 128, 0, 128, 0, 128, 128, 128, 128, 128,\n",
    "                # 64, 0, 0\n",
    "        #着色\n",
    "        img.putpalette(palette)\n",
    "        img.save(os.path.join(save_file,img_name))\n",
    "input_File= r'D:\\31890\\Pictures\\image\\Root_senescence\\clustering_image\\2\\hsv\\s_channel'\n",
    "save_File  = r'D:\\31890\\Pictures\\image\\Root_senescence\\clustering_image\\2\\hsv\\s_channel_clustering'\n",
    "colormap(input_File,save_File)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单通道灰度图提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def single_channel(Three_channel_img,color,save_file):\n",
    "    '''     Three_channel_img:三通道图片\n",
    "            color:颜色通道\n",
    "            save_file:保存路径      '''\n",
    "    #创建保存路径\n",
    "    save_file_list = []\n",
    "    for col in color:\n",
    "        if not os.path.exists(os.path.join(save_file,color,col+'_channel')):\n",
    "            path = os.makedirs(os.path.join(save_file,color,col+'_channel'))\n",
    "        save_file_list.append(os.path.join(save_file,color,col+'_channel'))\n",
    "    \n",
    "    for name in tqdm.tqdm(os.listdir(Three_channel_img)):\n",
    "        Tre_img_path = os.path.join(Three_channel_img, name)\n",
    "        image = cv2.imread(Tre_img_path)\n",
    "        #通道一\n",
    "        image1 = image[:, :, 0]\n",
    "        image1 = image1.astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(save_file_list[0], name), image1)\n",
    "        #通道二\n",
    "        image2 = image[:, :, 1]\n",
    "        image2 = image2.astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(save_file_list[1], name), image2)\n",
    "        #通道三\n",
    "        image3 = image[:, :, 2]\n",
    "        image3 = image3.astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(save_file_list[2], name), image3)\n",
    "\n",
    "Three_channel_img = r'D:\\31890\\Pictures\\image\\Root_senescence\\egnet_pre_cv2\\color_mask\\2'\n",
    "save_file = r'D:\\31890\\Pictures\\image\\Root_senescence\\channel_image\\2'\n",
    "single_channel(Three_channel_img,\"hsv\",save_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像和分割图融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将分割图和原图合在一起\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "def shwo(img_p1,img_p2):\n",
    "    image1 = Image.open(img_p1)     # 原图\n",
    "    image2 = Image.open(img_p2)     # 分割图\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(image1)\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.imshow(image2)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.imshow(image1)\n",
    "    plt.imshow(image2,alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "def fuse(img_p1,img_p2,save_p):\n",
    "    image1 = Image.open(img_p1)#image1 原图 \n",
    "    image2 = Image.open(img_p2)#image2 分割图\n",
    "\n",
    "    # image2.convert('L')\n",
    "    # palette = [0, 0, 0,0, 128, 0, 128, 128, 0,255,255,255]\n",
    "    # image2.putpalette(palette)\n",
    "    \n",
    "    image1 = image1.convert('RGBA')\n",
    "    image2 = image2.convert('RGBA')\n",
    "    \n",
    "    #两幅图像进行合并时，按公式：blended_img = img1 * (1 – alpha) + img2* alpha 进行\n",
    "    image = Image.blend(image1,image2,0.3)\n",
    "    image.save(save_p)\n",
    "    image.show()\n",
    "\n",
    "def cv_fuse(img_p1,img_p2,save_p):\n",
    "    imgfile = 'image.jpg'\n",
    "    pngfile = 'mask.png'\n",
    "\n",
    "    img = cv2.imread(imgfile, 1)\n",
    "    mask = cv2.imread(pngfile, 0)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(img, contours, -1, (0, 0, 255), 1)\n",
    "\n",
    "    img = img[:, :, ::-1]\n",
    "    img[..., 2] = np.where(mask == 1, 255, img[..., 2])\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "img_p1 = r\"D:\\software\\Code\\codefile\\Utils\\Image\\1.tif\"\n",
    "img_p2 = r'D:\\software\\Code\\codefile\\Utils\\Image\\3.tif'\n",
    "save_p = r'D:\\software\\Code\\codefile\\Utils\\Image\\4.tif'\n",
    "fuse(img_p1,img_p2,save_p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2聚类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGR = ([225,105,65],[0,255,255],[192,192,192],[255,255,240],[0,97,255],)\n",
    "\n",
    "\n",
    "def K_means_method_three_dim(image_path,k_means_path,n_class):\n",
    "    '''     image_path:三通道图片\n",
    "            k_means_path:聚类结果   '''\n",
    "            \n",
    "    img = cv2.imread(image_path,);\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #展平\n",
    "    image_flat = img.reshape(-1,3)\n",
    "    image_flat = np.float32(image_flat)\n",
    "    #终止条件\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TermCriteria_MAX_ITER, 20, 0.5)\n",
    "    #flags\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    #flags = cv2.KMEANS_PP_CENTERS\n",
    "    #K-Means聚类 聚集成4类\n",
    "    compactness, labels, centers = cv2.kmeans(image_flat, n_class, None, criteria, 10, flags)\n",
    "    #labels.shape=((3408500, 1))      centers.shape = ((4, 3))颜色矩阵\n",
    "    centers = np.uint8(centers)\n",
    "    for i in range(centers.shape[0]):\n",
    "        centers[i,:]\n",
    "        if centers[i,0]==centers[i,1]==centers[i,2]:\n",
    "                continue\n",
    "        else:\n",
    "                centers[i,:] = BGR[i]\n",
    "#     print(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    save = res.reshape((img.shape))\n",
    "    cv2.imwrite(k_means_path, save)\n",
    "\n",
    "image_path =r\"D:\\software\\Code\\code-file\\pytorch-template\\test\\cmask_sub.png\"\n",
    "k_means_path = r\"D:\\software\\Code\\code-file\\pytorch-template\\test\\cmask_sub_km.png\"\n",
    "K_means_method_three_dim(image_path,k_means_path,n_class=3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像的K-means聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单通道\n",
    "def K_means_method_one_dim(image_path,k_means_path):\n",
    "    '''     image_path:三通道图片\n",
    "            k_means_path:聚类结果   '''\n",
    "    img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    #展平\n",
    "    image_flat = img.reshape(-1, 1)\n",
    "    image_flat = np.float32(image_flat)\n",
    "    #终止条件\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TermCriteria_MAX_ITER, 20, 0.5)\n",
    "    #flags\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    #flags = cv2.KMEANS_PP_CENTERS\n",
    "    #K-Means聚类 聚集成4类\n",
    "    compactness, labels, centers = cv2.kmeans(image_flat, 4, None, criteria, 10, flags)\n",
    "    #labels.shape=((3408500, 1))      centers.shape = ((4, 3))\n",
    "    centers = np.uint8(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    save = res.reshape((img.shape))\n",
    "    cv2.imwrite(k_means_path, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三通道\n",
    "def K_means_method_three_dim(image_path,k_means_path):\n",
    "    '''     image_path:三通道图片\n",
    "            k_means_path:聚类结果   '''\n",
    "    img = cv2.imread(image_path)\n",
    "    #展平\n",
    "    image_flat = img.reshape(-1,3)\n",
    "    image_flat = np.float32(image_flat)\n",
    "    #终止条件\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TermCriteria_MAX_ITER, 20, 0.5)\n",
    "    #flags\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    #flags = cv2.KMEANS_PP_CENTERS\n",
    "    #K-Means聚类 聚集成4类\n",
    "    compactness, labels, centers = cv2.kmeans(image_flat, 5, None, criteria, 10, flags)\n",
    "    #labels.shape=((3408500, 1))      centers.shape = ((4, 3))\n",
    "    centers = np.uint8(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    save = res.reshape((img.shape))\n",
    "    cv2.imwrite(k_means_path, save)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2超像素"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,tqdm,cv2\n",
    "import numpy as np\n",
    "\n",
    "def Superpixel_segmentation(image_array):\n",
    "    #初始化slic项，超像素平均尺寸20（默认为10），平滑因子20\n",
    "    slic = cv2.ximgproc.createSuperpixelSLIC(image_array,region_size=50,ruler = 20)\n",
    "    slic.iterate(10)                                    #迭代次数，越大效果越好\n",
    "    mask_slic = slic.getLabelContourMask()              #获取Mask，超像素边缘Mask==1\n",
    "    label_slic = slic.getLabels()                       #获取超像素标签矩阵\n",
    "\n",
    "    cv2.imwrite(r'D:\\31890\\Desktop\\codefile\\Utils\\Image\\3.png',label_slic)\n",
    "\n",
    "    number_slic = slic.getNumberOfSuperpixels()         #获取超像素数目\n",
    "    print(number_slic)\n",
    "    mask_inv_slic = cv2.bitwise_not(mask_slic)\n",
    "\n",
    "\n",
    "    img_slic = cv2.bitwise_and(image_array,image_array,mask =  mask_inv_slic)  #在原图上绘制超像素边界\n",
    "    # cv2.imshow(\"img_slic\",img_slic)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return img_slic\n",
    "\n",
    "def Superpixel_averaging(image_array):\n",
    "    #初始化slic项，超像素平均尺寸20（默认为10），平滑因子20\n",
    "    slic = cv2.ximgproc.createSuperpixelSLIC(image_array,region_size=20,ruler = 40.0)\n",
    "    slic.iterate(10)                                    #迭代次数，越大效果越好\n",
    "    label_slic = slic.getLabels()                       #获取超像素标签\n",
    "    number_slic = slic.getNumberOfSuperpixels()         #获取超像素数目\n",
    "    color_array = np.zeros((number_slic,3))\n",
    "    for i in range(number_slic):\n",
    "        temp_array = image_array[label_slic==(i)]\n",
    "        temp_array_mean = np.mean(temp_array,axis=0)\n",
    "        color_array[i]=temp_array_mean\n",
    "    color_array = color_array.astype(np.int32)\n",
    "    result = color_array[(label_slic).flatten()]\n",
    "    result = result.reshape(image_array.shape)\n",
    "    return result\n",
    "\n",
    "image_array = cv2.imread(r\"D:\\31890\\Desktop\\codefile\\Utils\\Image\\2-2019-7-07-1200_8_13_.png\")\n",
    "result = Superpixel_segmentation(image_array)\n",
    "cv2.imwrite(r\"D:\\31890\\Desktop\\codefile\\Utils\\Image\\2.png\",result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 衰老超像素后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os,tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def shuailao_slic(image_array,mask_array):\n",
    "    #初始化slic项，超像素平均尺寸20（默认为10），平滑因子20\n",
    "    slic = cv2.ximgproc.createSuperpixelSLIC(image_array,region_size=20,ruler = 20)\n",
    "    slic.iterate(50)                                    #迭代次数，越大效果越好\n",
    "\n",
    "    label_slic = (slic.getLabels() +1).astype(np.uint8)                 #获取超像素标签矩阵\n",
    "    label_slic = cv2.bitwise_and(label_slic, label_slic, mask=mask_array.astype(np.uint8)).astype(np.uint8)\n",
    "\n",
    "    class_num = np.unique(label_slic,return_index=False,return_inverse=False)\n",
    "    for i in range(len(np.unique(label_slic,return_index=False,return_inverse=False))):\n",
    "        label_slic[np.where(label_slic==class_num[i])] = i  #重新排列分类矩阵\n",
    "\n",
    "    image_gray = cv2.cvtColor(image_array,cv2.COLOR_BGR2GRAY)\n",
    "    image_gray = cv2.bitwise_and(image_gray, image_gray, mask=mask_array).astype(np.uint8)\n",
    "\n",
    "    image_copy = image_gray.copy()\n",
    "\n",
    "    # a1,b1 = np.unique(image_gray,return_counts=True)\n",
    "    # print(a1,b1)\n",
    "\n",
    "    for i in range(len(class_num)):\n",
    "        a,b = np.unique(image_gray[label_slic==i],return_counts=True)\n",
    "        # print(a,b)\n",
    "        # print(a[np.argmax(b)])\n",
    "        if  a[np.argmax(b)]==0:\n",
    "            image_copy[np.where(label_slic==i)] = a[np.argmax(b)]\n",
    "            # a2,b2 = np.unique(image_copy[label_slic==i],return_counts=True)\n",
    "            # print(a2,b2)\n",
    "        elif a[np.argmax(b)]==141:\n",
    "            image_copy[np.where(label_slic==i)] = 1\n",
    "        elif a[np.argmax(b)]==76:\n",
    "            image_copy[np.where(label_slic==i)] = 2\n",
    "        else:\n",
    "            image_copy[np.where(label_slic==i)] = 3\n",
    "            \n",
    "\n",
    "    image_copy = Image.fromarray(image_copy)\n",
    "    image_copy.convert('L')\n",
    "    #调色板\n",
    "    palette = [0, 0, 0,0, 255, 0, 255, 0, 0,255,255,255]\n",
    "    # palette = [0, 0, 0, 128, 0, 0,0, 128, 0, 128, 128, 0,\n",
    "    #         0, 0, 128,]\n",
    "            # 128, 0, 128, 0, 128, 128, 128, 128, 128,\n",
    "            # 64, 0, 0\n",
    "    #着色\n",
    "    image_copy.putpalette(palette)\n",
    "\n",
    "    return image_copy\n",
    "\n",
    "def main(i,m,o):\n",
    "    if not os.path.exists(o):\n",
    "        os.makedirs(o)\n",
    "    for name in tqdm.tqdm(os.listdir(i)):\n",
    "        name  = name.split('.')[0]\n",
    "        image_array = cv2.imread(os.path.join(i,name+'.png'))\n",
    "        mask_array  = cv2.imread(os.path.join(m,name+'.png'),cv2.IMREAD_GRAYSCALE)\n",
    "        image_rebuild = shuailao_slic(image_array,mask_array)\n",
    "        image_rebuild.save(os.path.join(o,name+'.png'))\n",
    "\n",
    "i = r\"D:\\31890\\Desktop\\tranformer\\senescence\\shuailao\"\n",
    "m = r\"D:\\31890\\Desktop\\tranformer\\senescence\\mask_heidi\"\n",
    "o = r\"D:\\31890\\Desktop\\tranformer\\senescence\\shuailao_re2\"\n",
    "main(i,m,o)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分离主根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#滤波\n",
    "def blus(image_array):\n",
    "    img_blur=cv2.blur(image_array,(8,8))\n",
    "    return img_blur\n",
    "#阈值\n",
    "def threshold(image_array, lower, upper):\n",
    "    result = np.where(image_array>lower,255,0)\n",
    "    return result\n",
    "# Scharr算子实现梯度计算\n",
    "def Scharr_demo(image_array):\n",
    "    # x 方向梯度\n",
    "    image_grad_x = cv2.Scharr(image_array, cv2.CV_32F, 1, 0)\n",
    "    # 分别求绝对值并转化为8位的图像上，这样做方便显示\n",
    "    image_gradx = cv2.convertScaleAbs(image_grad_x) \n",
    "    return image_gradx\n",
    "#形态学操作\n",
    "def morphologyEx_demo(image_array):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,40))#3,40\n",
    "    result  = cv2.morphologyEx(image_array,cv2.MORPH_OPEN,kernel,iterations=4)\n",
    "    return result\n",
    "#图片相减\n",
    "def math_demo(image1_array,image2_array,add_or_sub=\"add\"):\n",
    "    if add_or_sub==\"add\":\n",
    "        image = image1_array + image2_array\n",
    "    if add_or_sub==\"sub\":\n",
    "        image = image1_array - image2_array\n",
    "    return image\n",
    "\n",
    "# 分割主根操作(基于egnet)\n",
    "#大图分割结果\n",
    "image1_file = r\"D:\\31890\\Desktop\\tranformer\\senescence\\mask_heidi\"\n",
    "save_file   = r\"D:\\31890\\Desktop\\tranformer\\senescence\\mask_heidi_notap\"\n",
    "if not os.path.exists(save_file):\n",
    "    os.makedirs(save_file)\n",
    "for name in tqdm.tqdm(os.listdir(image1_file)):\n",
    "    image1_path  = os.path.join(image1_file,name)\n",
    "    # image2_path  = os.path.join(image2_file,name)\n",
    "    save_path = os.path.join(save_file,name)\n",
    "    image = cv2.imread(image1_path,cv2.IMREAD_GRAYSCALE)\n",
    "    binary = threshold(image, 35, 255)\n",
    "    open_image = morphologyEx_demo(image)\n",
    "    y_grady = Scharr_demo(open_image)\n",
    "    image = math_demo(open_image,y_grady,'add')\n",
    "    blus_image = blus(image)\n",
    "    result = threshold(blus_image, 35, 255)\n",
    "    result = math_demo(binary,result,'sub')\n",
    "    cv2.imwrite(save_path,result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,tqdm\n",
    "import numpy as np\n",
    "\n",
    "def pixel_replacement(image_file,live_file):\n",
    "    if not os.path.exists(live_file):\n",
    "        os.makedirs(live_file)\n",
    "    for name in tqdm.tqdm(os.listdir(image_file)):\n",
    "        image_path = os.path.join(image_file,name)\n",
    "        save_live = os.path.join(live_file,name)\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img = np.where(img==38,255,0)\n",
    "\n",
    "\n",
    "        cv2.imwrite(save_live,img)\n",
    "image_file= r\"D:\\31890\\Desktop\\tranformer\\senescence\\hunhe\"\n",
    "live_file = r'D:\\31890\\Desktop\\tranformer\\senescence\\gray'\n",
    "pixel_replacement(image_file,live_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b72bce0f774da0affb1409740e09e5f72c8a559958be0d948f9a4e26f76c5539"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
