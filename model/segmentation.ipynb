{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-24T07:34:33.487366Z","iopub.status.busy":"2023-01-24T07:34:33.486888Z","iopub.status.idle":"2023-01-24T07:34:33.494106Z","shell.execute_reply":"2023-01-24T07:34:33.493026Z","shell.execute_reply.started":"2023-01-24T07:34:33.487330Z"},"trusted":true},"outputs":[],"source":["import torch,os,cv2\n","import albumentations as A\n","import torch.nn.functional as F\n","from torch import nn\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import DataLoader,Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-24T07:34:33.500166Z","iopub.status.busy":"2023-01-24T07:34:33.499367Z","iopub.status.idle":"2023-01-24T07:34:33.924271Z","shell.execute_reply":"2023-01-24T07:34:33.922785Z","shell.execute_reply.started":"2023-01-24T07:34:33.500126Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4, 3, 512, 512])\n","torch.Size([4, 512, 512])\n"]}],"source":["class MyDataset(Dataset):\n","    '''\n","    自定义加载数据集\n","    '''\n","    def __init__(self,data_dir,train=True,trans_imgs=True):\n","        self.data_dir = data_dir\n","        self.train = train\n","        self.trans_imgs = trans_imgs\n","\n","        #建立数据列表\n","        images,labels = [],[]\n","        if self.train:\n","            for name in os.listdir(os.path.join(data_dir,'imgs','train')):\n","                images.append(os.path.join(data_dir,'imgs','train',name))\n","                labels.append(os.path.join(data_dir,'anno','train',name.split('.')[0]+'.png'))\n","        else:\n","            for name in os.listdir(os.path.join(data_dir,'imgs','test')):\n","                images.append(os.path.join(data_dir,'imgs','test',name))\n","                labels.append(os.path.join(data_dir,'anno','test',name.split('.')[0]+'.png'))\n","        self.labels = labels \n","        self.images = images\n","        \n","    def __getitem__(self, index):\n","        #读取图像\n","        img_path,label_path =  self.images[index],self.labels[index]\n","        imgs = cv2.imread(img_path)\n","        imgs = cv2.cvtColor(imgs, cv2.COLOR_BGR2RGB)\n","        lbls = cv2.imread(label_path,cv2.IMREAD_GRAYSCALE)\n","        transform = self.transform(self.trans_imgs)\n","        transformed = transform(image=imgs, mask=lbls)\n","        imgs = transformed['image']\n","        lbls = transformed['mask'].long()\n","\n","        return imgs,lbls\n","    \n","    def __len__(self):\n","        return len(self.images)\n","    \n","    def transform(self,trans):\n","        # Declare an augmentation pipeline\n","        if trans:\n","            transform = A.Compose([\n","                A.RandomResizedCrop(height=512,width=512,scale=(0.15, 1.0)),\n","                #旋转\n","                A.Rotate(p=0.3),\n","                #翻转\n","                A.HorizontalFlip(p=0.3),\n","                A.VerticalFlip(p=0.2),\n","                A.OneOf([\n","                    #随机改变图像的亮度、对比度和饱和度\n","                    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.1),\n","                    #随机改变输入图像的色调、饱和度和值\n","                    A.HueSaturationValue(p=0.3),\n","                    ],p=0.2),\n","                A.Normalize (mean=[0.4754358, 0.35509014, 0.282971],std=[0.16318515, 0.15616792, 0.15164918], max_pixel_value=255.0, always_apply=False, p=1.0),\n","                ToTensorV2()\n","            ])\n","        else:\n","            transform = A.Compose([\n","                A.RandomResizedCrop(height=512,width=512,scale=(0.85, 1.0)),\n","                ToTensorV2()\n","            ])\n","        return transform\n","\n","def test_data():\n","    data_dir = r'/kaggle/input/root-data/my_data'\n","    batch_size = 4\n","    mydata = MyDataset(data_dir,train=False)\n","    mydataloader = DataLoader(mydata, batch_size, shuffle=False,num_workers=1)\n","    img_tensor1,img_tensor2 = next(iter(mydataloader))\n","    # show(batch_size,img_tensor1,img_tensor2)\n","    print(img_tensor1.shape)\n","    print(img_tensor2.shape)\n","# test_data()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-01-24T07:34:33.927022Z","iopub.status.busy":"2023-01-24T07:34:33.926620Z","iopub.status.idle":"2023-01-24T07:34:39.919659Z","shell.execute_reply":"2023-01-24T07:34:39.918708Z","shell.execute_reply.started":"2023-01-24T07:34:33.926984Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 2, 512, 512])\n"]}],"source":["def initialize_weights(*models):\n","    for model in models:\n","        for module in model.modules():\n","            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","                nn.init.kaiming_normal_(module.weight)\n","                if module.bias is not None:\n","                    module.bias.data.zero_()\n","            elif isinstance(module, nn.BatchNorm2d):\n","                module.weight.data.fill_(1)\n","                module.bias.data.zero_()\n","\n","\n","class _EncoderBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout=False):\n","        super(_EncoderBlock, self).__init__()\n","        layers = [\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        ]\n","        if dropout:\n","            layers.append(nn.Dropout())\n","        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.encode = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return self.encode(x)\n","\n","\n","class _DecoderBlock(nn.Module):\n","    def __init__(self, in_channels, middle_channels, out_channels):\n","        super(_DecoderBlock, self).__init__()\n","        self.decode = nn.Sequential(\n","            nn.Conv2d(in_channels, middle_channels, kernel_size=3),\n","            nn.BatchNorm2d(middle_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(middle_channels, middle_channels, kernel_size=3),\n","            nn.BatchNorm2d(middle_channels),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=2, stride=2),\n","        )\n","\n","    def forward(self, x):\n","        return self.decode(x)\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(UNet, self).__init__()\n","        self.enc1 = _EncoderBlock(3, 64)\n","        self.enc2 = _EncoderBlock(64, 128)\n","        self.enc3 = _EncoderBlock(128, 256)\n","        self.enc4 = _EncoderBlock(256, 512, dropout=True)\n","        self.center = _DecoderBlock(512, 1024, 512)\n","        self.dec4 = _DecoderBlock(1024, 512, 256)\n","        self.dec3 = _DecoderBlock(512, 256, 128)\n","        self.dec2 = _DecoderBlock(256, 128, 64)\n","        self.dec1 = nn.Sequential(\n","            nn.Conv2d(128, 64, kernel_size=3),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","        )\n","        self.final = nn.Conv2d(64, num_classes, kernel_size=1)\n","        initialize_weights(self)\n","\n","    def forward(self, x):\n","        enc1 = self.enc1(x)\n","        enc2 = self.enc2(enc1)\n","        enc3 = self.enc3(enc2)\n","        enc4 = self.enc4(enc3)\n","        center = self.center(enc4)\n","        dec4 = self.dec4(torch.cat([center, F.interpolate(enc4, center.size()[2:], mode='bilinear')], 1))\n","        dec3 = self.dec3(torch.cat([dec4, F.interpolate(enc3, dec4.size()[2:], mode='bilinear')], 1))\n","        dec2 = self.dec2(torch.cat([dec3, F.interpolate(enc2, dec3.size()[2:], mode='bilinear')], 1))\n","        dec1 = self.dec1(torch.cat([dec2, F.interpolate(enc1, dec2.size()[2:], mode='bilinear')], 1))\n","        final = self.final(dec1)\n","        return F.interpolate(final, x.size()[2:], mode='bilinear')\n","\n","def run():\n","    net = UNet(2)\n","    x = torch.rand(2,3,512,512)\n","    y = net(x) \n","    print(y.shape)\n","run()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-24T07:34:39.922393Z","iopub.status.busy":"2023-01-24T07:34:39.921906Z","iopub.status.idle":"2023-01-24T07:34:39.945544Z","shell.execute_reply":"2023-01-24T07:34:39.944449Z","shell.execute_reply.started":"2023-01-24T07:34:39.922342Z"},"trusted":true},"outputs":[],"source":["def check_mkdir(dir_name):\n","    if not os.path.exists(dir_name):\n","        os.mkdir(dir_name)\n","\n","class CrossEntropyLoss2d(nn.Module):\n","    def __init__(self, weight=None, size_average=True, ignore_index=255):\n","        super(CrossEntropyLoss2d, self).__init__()\n","        self.nll_loss = nn.NLLLoss2d(weight, size_average, ignore_index)\n","\n","    def forward(self, inputs, targets):\n","        return self.nll_loss(F.log_softmax(inputs), targets)\n","    \n","def evaluate(predictions, gts, num_classes):\n","    hist = np.zeros((num_classes, num_classes))\n","    for lp, lt in zip(predictions, gts):\n","        hist += _fast_hist(lp.flatten(), lt.flatten(), num_classes)\n","    # axis 0: gt, axis 1: prediction\n","    acc = np.diag(hist).sum() / hist.sum()\n","    acc_cls = np.diag(hist) / hist.sum(axis=1)\n","    acc_cls = np.nanmean(acc_cls)\n","    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n","    mean_iu = np.nanmean(iu)\n","    freq = hist.sum(axis=1) / hist.sum()\n","    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n","    return acc, acc_cls, mean_iu, fwavacc\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def prepare_device():\n","    \n","    n_gpu = torch.cuda.device_count()\n","    if n_gpu_use > 0 and n_gpu == 0:\n","        print(\"Warning: There\\'s no GPU available on this machine,\"\n","              \"training will be performed on CPU.\")\n","        n_gpu_use = 0\n","    if n_gpu_use > n_gpu:\n","        print(f\"Warning: The number of GPU\\'s configured to use is {n_gpu_use}, but only {n_gpu} are \"\n","              \"available on this machine.\")\n","        n_gpu_use = n_gpu\n","    device = torch.device('cuda:0' if n_gpu_use > 0 else 'cpu')\n","    list_ids = list(range(n_gpu_use))\n","    return device, list_ids\n","\n","def colorize_mask(mask):\n","    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n","    new_mask.putpalette(palette)\n","    return new_mask"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-24T07:34:39.949183Z","iopub.status.busy":"2023-01-24T07:34:39.948272Z","iopub.status.idle":"2023-01-24T07:34:39.963763Z","shell.execute_reply":"2023-01-24T07:34:39.962563Z","shell.execute_reply.started":"2023-01-24T07:34:39.949139Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: There's no GPU available on this machine,training will be performed on CPU.\n"]}],"source":["def prepare_device(n_gpu_use):\n","    \n","    n_gpu = torch.cuda.device_count()\n","    if n_gpu_use > 0 and n_gpu == 0:\n","        print(\"Warning: There\\'s no GPU available on this machine,\"\n","              \"training will be performed on CPU.\")\n","        n_gpu_use = 0\n","    if n_gpu_use > n_gpu:\n","        print(f\"Warning: The number of GPU\\'s configured to use is {n_gpu_use}, but only {n_gpu} are \"\n","              \"available on this machine.\")\n","        n_gpu_use = n_gpu\n","    device = torch.device('cuda:0' if n_gpu_use > 0 else 'cpu')\n","    list_ids = list(range(n_gpu_use))\n","    return device, list_ids\n","device, list_ids = prepare_device(1)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-24T07:48:03.642601Z","iopub.status.busy":"2023-01-24T07:48:03.642208Z","iopub.status.idle":"2023-01-24T07:48:13.905444Z","shell.execute_reply":"2023-01-24T07:48:13.903694Z","shell.execute_reply.started":"2023-01-24T07:48:03.642571Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: There's no GPU available on this machine,training will be performed on CPU.\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:217: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n","  warnings.warn(\"NLLLoss2d has been deprecated. \"\n","/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"ename":"IndexError","evalue":"invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3278117194.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/3278117194.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_args)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr_patience'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch_num'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3278117194.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, net, criterion, optimizer, epoch, train_args)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mcurr_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"]}],"source":["import datetime\n","import os\n","import random\n","\n","import torchvision.transforms as standard_transforms\n","import torchvision.utils as vutils\n","from tensorboardX import SummaryWriter\n","from torch import optim\n","from torch.autograd import Variable\n","from torch.backends import cudnn\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.utils.data import DataLoader\n","\n","cudnn.benchmark = True\n","\n","ckpt_path = '../../ckpt'\n","exp_name = 'voc-fcn8s'\n","# writer = SummaryWriter(os.path.join(ckpt_path, 'exp', exp_name))\n","\n","args = {\n","    'epoch_num': 300,\n","    'lr': 1e-10,\n","    'weight_decay': 1e-4,\n","    'momentum': 0.95,\n","    'lr_patience': 100,  # large patience denotes fixed lr\n","    'snapshot': '',  # empty string denotes learning from scratch\n","    'print_freq': 20,\n","    'val_save_to_img_file': False,\n","    'val_img_sample_rate': 0.1,  # randomly sample some validation results to display,\n","    'num_classes': 2\n","}\n","\n","\n","def main(train_args):\n","    \n","    device, list_ids = prepare_device(1)\n","    \n","    net = UNet(train_args['num_classes']).to(device)\n","\n","    if len(train_args['snapshot']) == 0:\n","        curr_epoch = 1\n","        train_args['best_record'] = {'epoch': 0, 'val_loss': 1e10, 'acc': 0, 'acc_cls': 0, 'mean_iu': 0, 'fwavacc': 0}\n","    else:\n","        print('training resumes from ' + train_args['snapshot'])\n","        net.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, train_args['snapshot'])))\n","        split_snapshot = train_args['snapshot'].split('_')\n","        curr_epoch = int(split_snapshot[1]) + 1\n","        train_args['best_record'] = {'epoch': int(split_snapshot[1]), 'val_loss': float(split_snapshot[3]),\n","                                     'acc': float(split_snapshot[5]), 'acc_cls': float(split_snapshot[7]),\n","                                     'mean_iu': float(split_snapshot[9]), 'fwavacc': float(split_snapshot[11])}\n","\n","    net.train()\n","    \n","    data_dir = r'/kaggle/input/root-data/my_data'\n","    train_set = MyDataset(data_dir)\n","    train_loader = DataLoader(train_set, batch_size=1, num_workers=4, shuffle=True)\n","    val_set = MyDataset(data_dir,train=False,trans_imgs=False)\n","    val_loader = DataLoader(val_set, batch_size=1, num_workers=4, shuffle=False)\n","\n","    criterion = CrossEntropyLoss2d(size_average=False, ignore_index=255).to(device)\n","\n","    optimizer = optim.Adam([\n","        {'params': [param for name, param in net.named_parameters() if name[-4:] == 'bias'],\n","         'lr': 2 * train_args['lr']},\n","        {'params': [param for name, param in net.named_parameters() if name[-4:] != 'bias'],\n","         'lr': train_args['lr'], 'weight_decay': train_args['weight_decay']}\n","    ], betas=(train_args['momentum'], 0.999))\n","\n","    if len(train_args['snapshot']) > 0:\n","        optimizer.load_state_dict(torch.load(os.path.join(ckpt_path, exp_name, 'opt_' + train_args['snapshot'])))\n","        optimizer.param_groups[0]['lr'] = 2 * train_args['lr']\n","        optimizer.param_groups[1]['lr'] = train_args['lr']\n","\n","    check_mkdir(ckpt_path)\n","    check_mkdir(os.path.join(ckpt_path, exp_name))\n","    open(os.path.join(ckpt_path, exp_name, str(datetime.datetime.now()) + '.txt'), 'w').write(str(train_args) + '\\n\\n')\n","\n","    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=train_args['lr_patience'], min_lr=1e-10, verbose=True)\n","    for epoch in range(curr_epoch, train_args['epoch_num'] + 1):\n","        train(train_loader, net, criterion, optimizer, epoch, train_args)\n","        val_loss = validate(val_loader, net, criterion, optimizer, epoch, train_args, restore_transform, visualize)\n","        scheduler.step(val_loss)\n","\n","\n","def train(train_loader, net, criterion, optimizer, epoch, train_args):\n","    train_loss = AverageMeter()\n","    curr_iter = (epoch - 1) * len(train_loader)\n","    for i, data in enumerate(train_loader):\n","        inputs, labels = data\n","        assert inputs.size()[2:] == labels.size()[1:]\n","        N = inputs.size(0)\n","        if torch.cuda.is_available():\n","            inputs = Variable(inputs).cuda()\n","            labels = Variable(labels).cuda()\n","\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        assert outputs.size()[2:] == labels.size()[1:]\n","        assert outputs.size()[1] == train_args['num_classes']\n","\n","        loss = criterion(outputs, labels) / N\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss.update(loss[0].data, N)\n","\n","        curr_iter += 1\n","        writer.add_scalar('train_loss', train_loss.avg, curr_iter)\n","\n","        if (i + 1) % train_args['print_freq'] == 0:\n","            print('[epoch %d], [iter %d / %d], [train loss %.5f]' % (\n","                epoch, i + 1, len(train_loader), train_loss.avg\n","            ))\n","\n","\n","def validate(val_loader, net, criterion, optimizer, epoch, train_args, restore, visualize):\n","    net.eval()\n","\n","    val_loss = AverageMeter()\n","    inputs_all, gts_all, predictions_all = [], [], []\n","\n","    for vi, data in enumerate(val_loader):\n","        inputs, gts = data\n","        N = inputs.size(0)\n","        inputs = Variable(inputs, volatile=True).cuda()\n","        gts = Variable(gts, volatile=True).cuda()\n","\n","        outputs = net(inputs)\n","        predictions = outputs.data.max(1)[1].squeeze_(1).squeeze_(0).cpu().numpy()\n","\n","        val_loss.update(criterion(outputs, gts).data[0] / N, N)\n","\n","        if random.random() > train_args['val_img_sample_rate']:\n","            inputs_all.append(None)\n","        else:\n","            inputs_all.append(inputs.data.squeeze_(0).cpu())\n","        gts_all.append(gts.data.squeeze_(0).cpu().numpy())\n","        predictions_all.append(predictions)\n","\n","    acc, acc_cls, mean_iu, fwavacc = evaluate(predictions_all, gts_all, train_args['num_classes'])\n","\n","    if mean_iu > train_args['best_record']['mean_iu']:\n","        train_args['best_record']['val_loss'] = val_loss.avg\n","        train_args['best_record']['epoch'] = epoch\n","        train_args['best_record']['acc'] = acc\n","        train_args['best_record']['acc_cls'] = acc_cls\n","        train_args['best_record']['mean_iu'] = mean_iu\n","        train_args['best_record']['fwavacc'] = fwavacc\n","        snapshot_name = 'epoch_%d_loss_%.5f_acc_%.5f_acc-cls_%.5f_mean-iu_%.5f_fwavacc_%.5f_lr_%.10f' % (\n","            epoch, val_loss.avg, acc, acc_cls, mean_iu, fwavacc, optimizer.param_groups[1]['lr']\n","        )\n","        torch.save(net.state_dict(), os.path.join(ckpt_path, exp_name, snapshot_name + '.pth'))\n","        torch.save(optimizer.state_dict(), os.path.join(ckpt_path, exp_name, 'opt_' + snapshot_name + '.pth'))\n","\n","        if train_args['val_save_to_img_file']:\n","            to_save_dir = os.path.join(ckpt_path, exp_name, str(epoch))\n","            check_mkdir(to_save_dir)\n","\n","        val_visual = []\n","        for idx, data in enumerate(zip(inputs_all, gts_all, predictions_all)):\n","            if data[0] is None:\n","                continue\n","            input_pil = restore(data[0])\n","            gt_pil = colorize_mask(data[1])\n","            predictions_pil = colorize_mask(data[2])\n","            if train_args['val_save_to_img_file']:\n","                input_pil.save(os.path.join(to_save_dir, '%d_input.png' % idx))\n","                predictions_pil.save(os.path.join(to_save_dir, '%d_prediction.png' % idx))\n","                gt_pil.save(os.path.join(to_save_dir, '%d_gt.png' % idx))\n","            val_visual.extend([visualize(input_pil.convert('RGB')), visualize(gt_pil.convert('RGB')),\n","                               visualize(predictions_pil.convert('RGB'))])\n","        val_visual = torch.stack(val_visual, 0)\n","        val_visual = vutils.make_grid(val_visual, nrow=3, padding=5)\n","        writer.add_image(snapshot_name, val_visual)\n","\n","    print('--------------------------------------------------------------------')\n","    print('[epoch %d], [val loss %.5f], [acc %.5f], [acc_cls %.5f], [mean_iu %.5f], [fwavacc %.5f]' % (\n","        epoch, val_loss.avg, acc, acc_cls, mean_iu, fwavacc))\n","\n","    print('best record: [val loss %.5f], [acc %.5f], [acc_cls %.5f], [mean_iu %.5f], [fwavacc %.5f], [epoch %d]' % (\n","        train_args['best_record']['val_loss'], train_args['best_record']['acc'], train_args['best_record']['acc_cls'],\n","        train_args['best_record']['mean_iu'], train_args['best_record']['fwavacc'], train_args['best_record']['epoch']))\n","\n","    print('--------------------------------------------------------------------')\n","\n","    writer.add_scalar('val_loss', val_loss.avg, epoch)\n","    writer.add_scalar('acc', acc, epoch)\n","    writer.add_scalar('acc_cls', acc_cls, epoch)\n","    writer.add_scalar('mean_iu', mean_iu, epoch)\n","    writer.add_scalar('fwavacc', fwavacc, epoch)\n","    writer.add_scalar('lr', optimizer.param_groups[1]['lr'], epoch)\n","\n","    net.train()\n","    return val_loss.avg\n","\n","\n","if __name__ == '__main__':\n","    main(args)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"b72bce0f774da0affb1409740e09e5f72c8a559958be0d948f9a4e26f76c5539"}}},"nbformat":4,"nbformat_minor":4}
